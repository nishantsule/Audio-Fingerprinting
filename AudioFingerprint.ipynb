{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from scipy.signal import spectrogram\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import compare_ssim\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import pyaudio\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure \n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFP():\n",
    "    ## Initializing AudioFP object properties\n",
    "    def __init__(self):\n",
    "        audio_type = input('Do you wish to read from a file or record? Enter \"r\" to read and \"a\" to record: ')\n",
    "        if audio_type == 'r':\n",
    "            filename = input('Enter the filename you want to read including the extension: ')\n",
    "            self.songname = filename\n",
    "            self.channels = []\n",
    "            self.framerate = []\n",
    "            self.read_audiofile(plot=True)\n",
    "        elif audio_type=='a':\n",
    "            filename = input('Enter a name for the recording:')\n",
    "            self.songname = filename\n",
    "            self.channels = []\n",
    "            self.framerate = []    \n",
    "            self.record_audiofile(plot=True)\n",
    "        else:\n",
    "            sys.exit('Error: Incorrect entry. Enter \"r\" to read an audio file or \"a\" to record')\n",
    "\n",
    "        \n",
    "    ## Read audio file using pydub and plot signal\n",
    "    def read_audiofile(self, plot):\n",
    "        songdata = []\n",
    "        audiofile = AudioSegment.from_file(self.songname)\n",
    "        songdata = np.frombuffer(audiofile._data, np.int16)\n",
    "        for chn in range(audiofile.channels):\n",
    "            self.channels.append(songdata[chn::audiofile.channels])\n",
    "        self.framerate = audiofile.frame_rate\n",
    "        # Plot time signal\n",
    "        if plot:\n",
    "            p1 = figure(plot_width=900, plot_height=500, title='Audio Signal', \n",
    "                        x_axis_label='Time (s)', y_axis_label='Amplitude (arb. units)')\n",
    "            time = np.linspace(0, len(self.channels[0])/self.framerate, len(self.channels[0]))\n",
    "            p1.line(time[0::1000], self.channels[0][0::1000])\n",
    "            show(p1)\n",
    "            \n",
    "    ## Record audio file using pyaudio and plot signal\n",
    "    def record_audiofile(self, plot):\n",
    "        rec_time = int(input('How long do you want to record? Enter time in seconds: '))\n",
    "        start_rec = input('Do you want to start recoding? Enter \"y\" to start:')\n",
    "        if start_rec=='y':\n",
    "            chk_size = 8192  # chunk size\n",
    "            fmt = pyaudio.paInt16  # format of audio \n",
    "            chan = 2  # Number of channels \n",
    "            samp_rate = 44100  # sampling rate\n",
    "            self.framerate = samp_rate\n",
    "            p = pyaudio.PyAudio()\n",
    "            astream = p.open(format=fmt, channels=chan, rate=samp_rate,\n",
    "                             input=True, frames_per_buffer=chk_size)\n",
    "            songdata = []\n",
    "            self.channels = [[] for i in range(chan)]\n",
    "            for i in range(0, np.int(samp_rate / chk_size * rec_time)):\n",
    "                songdata = astream.read(chk_size)\n",
    "                nums = np.fromstring(songdata, dtype=np.int16)\n",
    "                for c in range(chan):\n",
    "                    self.channels[c].extend(nums[c::chan])\n",
    "            # Close audio stream\n",
    "            astream.stop_stream()\n",
    "            astream.close()\n",
    "            p.terminate()\n",
    "        else:\n",
    "            sys.exit('Audio recording did not start. Start over again.')\n",
    "        # Plot time signal\n",
    "        if plot:\n",
    "            p1 = figure(plot_width=900, plot_height=500, title='Audio Signal', \n",
    "                        x_axis_label='Time (s)', y_axis_label='Amplitude (arb. units)')\n",
    "            time = np.linspace(0, len(self.channels[0])/self.framerate, len(self.channels[0]))\n",
    "            p1.line(time[0::100], self.channels[0][0::100])\n",
    "            show(p1)\n",
    "        \n",
    "    ## Generate and plot spectrogram of audio data\n",
    "    def generate_spectrogram(self, plot):\n",
    "        audiosignal = np.sum(self.channels, axis=0) / len(self.channels)  # Averaging signal over all channels\n",
    "        fs = self.framerate  # sampling rate\n",
    "        window = 'hamming'  # window function\n",
    "        nperseg = 10 * 256  # window size\n",
    "        overlap_ratio = 0.5  # degree of overlap, larger number->more overlap, denser fingerprint\n",
    "        noverlap = int(overlap_ratio * nperseg)  # number of points to overlap\n",
    "        # generate spectrogram from consecutive FFTs over the defined window\n",
    "        self.f, self.t, self.sgram = spectrogram(audiosignal, fs, window, nperseg, noverlap)  \n",
    "        self.sgram = 10 * np.log10(self.sgram)  # transmorm linear output to dB scale \n",
    "        self.sgram[self.sgram == -np.inf] = 0  # replace infs with zeros\n",
    "        # Plot Spectrogram\n",
    "        if plot:\n",
    "            p2 = figure(plot_width=900, plot_height=500, title='Spectrogram',\n",
    "                        x_axis_label='Time (s)', y_axis_label='Frequency (Hz)',\n",
    "                        x_range=(min(self.t), max(self.t)), y_range=(min(self.f), max(self.f)))\n",
    "            p2.image([self.sgram[::2, ::2]], x=min(self.t), y=min(self.f), \n",
    "                     dw=max(self.t), dh=max(self.f), palette='Spectral11')\n",
    "            show(p2)\n",
    "        \n",
    "    ## Find peaks in the spectrogram using image processing\n",
    "    def find_peaks(self, plot):\n",
    "        min_peak_sep = 20  # larger sep -> less peaks -> less accuracy, but faster fingerprinting\n",
    "        min_peak_amp = 15  # larger min amp -> less peaks -> less accuracy, but faster fingerprinting\n",
    "        coordinates = peak_local_max(self.sgram, min_distance=min_peak_sep, indices=True,\n",
    "                                     threshold_abs=min_peak_amp)\n",
    "        \n",
    "        self.peaks = self.sgram[coordinates[:, 0], coordinates[:, 1]]\n",
    "        self.tp = self.t[coordinates[:, 1]]\n",
    "        self.fp = self.f[coordinates[:, 0]]\n",
    "        # Plot the peaks detected on the spectrogram\n",
    "        if plot:\n",
    "            p3 = figure(plot_width=900, plot_height=500, title='Spectrogram with Peaks',\n",
    "                        x_axis_label='Time (s)', y_axis_label='Frequency (Hz)',\n",
    "                        x_range=(min(self.t), max(self.t)), y_range=(min(self.f), max(self.f)))\n",
    "            p3.image([self.sgram[::2, ::2]], x=min(self.t), y=min(self.f), \n",
    "                     dw=max(self.t), dh=max(self.f), palette='Spectral11')\n",
    "            p3.scatter(self.tp, self.fp)\n",
    "            show(p3)\n",
    "        \n",
    "    ## Use the peak data from the spectrogram to generate a string with pairs of \n",
    "    ## peak frequencies and the time delta between them \n",
    "    def generate_fingerprint(self, plot):\n",
    "        peak_connectivity = 5  # Number of neighboring peaks to use as target for each anchor\n",
    "        peak_time_delta_min = 0  # Minimum spacing in time between peaks for anchor and target\n",
    "        peak_time_delta_max = 20  # Maximum spacing in time between peaks for anchor and target\n",
    "        # Create the the data to be used for fingerprinting\n",
    "        # for each frequency (anchor) find the next few frequencies (targets) and calculate their time deltas\n",
    "        # the anchor-target frequency pairs and their time deltas will be used to generate the fingerprints\n",
    "        s = []  # Empty list to contain data for fingerprint\n",
    "        for i in range(len(self.peaks)):\n",
    "            for j in range(1, peak_connectivity):\n",
    "                if (i + j) < len(self.peaks):\n",
    "                    f1 = self.fp[i]\n",
    "                    f2 = self.fp[i + j]\n",
    "                    t1 = self.tp[i]\n",
    "                    t2 = self.tp[i + j]\n",
    "                    t_delta = t2 - t1\n",
    "                    if t_delta >= peak_time_delta_min and t_delta <= peak_time_delta_max:\n",
    "                        s.append(str(np.rint(f1)) + str(np.rint(f2)) + str(np.rint(t_delta)))\n",
    "        self.fingerprint = MinHash(num_perm=128)\n",
    "        for data in s:\n",
    "            self.fingerprint.update(data.encode('utf8'))\n",
    "        if plot:\n",
    "            print('{} audio-fingprint: '.format(self.songname))\n",
    "            print(self.fingerprint.digest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare fingerprints of two songs and calculate percentage of match\n",
    "def compare_fingerprints(s1, s2, cmp_type):\n",
    "    sim_threshold = 0.5\n",
    "    lsh = MinHashLSH(threshold=sim_threshold, num_perm=128)\n",
    "    lsh.insert('song1', s1)\n",
    "    lsh_result = lsh.query(s2)\n",
    "    if not lsh_result:\n",
    "        print('Not a match, Jaccard similarity < {}'.format(sim_threshold))\n",
    "    else:\n",
    "        print('Match, Jaccard similarity > {}'.format(sim_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create song object. Select whether to read an audiofile from file or record using the microphone.\n",
    "# Provide full file name including extension.\n",
    "# Plots the audio signal\n",
    "song1 = AudioFP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use audio signal from above file to generate spectrogram\n",
    "song1.generate_spectrogram(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find local maxima in the spectrogram to generate the audio fingerprint \n",
    "song1.find_peaks(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use peaks in the spectrogram to generate a fingerprint for the audio signal\n",
    "song1.generate_fingerprint(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "song2 = AudioFP()\n",
    "song2.generate_spectrogram(plot=False)\n",
    "song2.find_peaks(plot=False)\n",
    "song2.generate_fingerprint(plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_fingerprints(song1.fingerprint, song2.fingerprint, 'lsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
